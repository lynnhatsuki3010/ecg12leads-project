{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ef9224-0d70-4e94-9c21-8eaef2c65488",
   "metadata": {},
   "source": [
    "# **IMPORT TH∆Ø VI·ªÜN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e77c4ba-788e-4f1e-8ba4-3a33e9f48963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thi·∫øt b·ªã s·ª≠ d·ª•ng: cuda\n"
     ]
    }
   ],
   "source": [
    "# üìò 02_training.ipynb\n",
    "# Nhi·ªám v·ª•: Hu·∫•n luy·ªán m√¥ h√¨nh ResNet1D + Attention cho ECG 12 leads\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from training.dataset_loader import ECGDataset\n",
    "from training.model import ResNet1DAttention\n",
    "from training.model_inceptiontime import InceptionTime1D\n",
    "from training.train import train_model\n",
    "from training.evaluate import evaluate_model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Thi·∫øt b·ªã s·ª≠ d·ª•ng:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd59f9d7-340e-4da6-8fe6-4eb08ba696f0",
   "metadata": {},
   "source": [
    "# **ƒê·ªåC D·ªÆ LI·ªÜU CHIA TRAIN/VAL/TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72abad9d-1545-4758-b02b-7d9aa1e75708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 31393 | Val: 4485 | Test: 8970\n",
      "S·ªë l·ªõp nh√£n: 8\n"
     ]
    }
   ],
   "source": [
    "# === 1Ô∏è‚É£ ƒê·ªçc d·ªØ li·ªáu chia train/val/test ===\n",
    "data_dir = r\"E:\\NCKH - 2026\\ECG Project\\data\\processed\\splits\"\n",
    "\n",
    "X_train = np.load(os.path.join(data_dir, \"train_files.npy\"), allow_pickle=True)\n",
    "X_val = np.load(os.path.join(data_dir, \"val_files.npy\"), allow_pickle=True)\n",
    "X_test = np.load(os.path.join(data_dir, \"test_files.npy\"), allow_pickle=True)\n",
    "\n",
    "y_train = np.load(os.path.join(data_dir, \"y_train.npy\"))\n",
    "y_val = np.load(os.path.join(data_dir, \"y_val.npy\"))\n",
    "y_test = np.load(os.path.join(data_dir, \"y_test.npy\"))\n",
    "\n",
    "print(f\"Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "print(f\"S·ªë l·ªõp nh√£n: {y_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019c1a20-9651-42ff-a45d-48619ac4f61e",
   "metadata": {},
   "source": [
    "# **T·∫†O DATASET - DATA LOADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5cc1682-4f54-43de-9109-9cc5c1485d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DataLoader ƒë√£ s·∫µn s√†ng\n"
     ]
    }
   ],
   "source": [
    "# === 2Ô∏è‚É£ T·∫°o Dataset & DataLoader ===\n",
    "train_dataset = ECGDataset(X_train, y_train, augment=True)\n",
    "val_dataset = ECGDataset(X_val, y_val)\n",
    "test_dataset = ECGDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"‚úÖ DataLoader ƒë√£ s·∫µn s√†ng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c16c2-d382-4775-b54f-1e3071ff7b52",
   "metadata": {},
   "source": [
    "# **TRAIN D·ªÆ LI·ªÜU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d203ae-2427-44ea-82af-1253812d7fe6",
   "metadata": {},
   "source": [
    "# **RESNET18**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "284993cd-6b2e-463b-b3dc-7f347ee34c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet1DAttention(\n",
      "  (layer1): BasicBlock1D(\n",
      "    (conv1): Conv1d(12, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Conv1d(12, 64, kernel_size=(1,), stride=(2,))\n",
      "  )\n",
      "  (layer2): BasicBlock1D(\n",
      "    (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Conv1d(64, 128, kernel_size=(1,), stride=(2,))\n",
      "  )\n",
      "  (layer3): BasicBlock1D(\n",
      "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Conv1d(128, 128, kernel_size=(1,), stride=(2,))\n",
      "  )\n",
      "  (attention): Attention(\n",
      "    (attn): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=8, bias=True)\n",
      ")\n",
      "Epoch 1: train_loss=0.7548, val_loss=0.6599\n",
      "Epoch 2: train_loss=0.6179, val_loss=0.5770\n",
      "Epoch 3: train_loss=0.5668, val_loss=0.5929\n",
      "Epoch 4: train_loss=0.5476, val_loss=0.5964\n",
      "Epoch 5: train_loss=0.5260, val_loss=0.5460\n",
      "Epoch 6: train_loss=0.5112, val_loss=0.5363\n",
      "Epoch 7: train_loss=0.4984, val_loss=0.5255\n",
      "Epoch 8: train_loss=0.4879, val_loss=0.5175\n",
      "Epoch 9: train_loss=0.4758, val_loss=0.5123\n",
      "Epoch 10: train_loss=0.4658, val_loss=0.5055\n",
      "Epoch 11: train_loss=0.4625, val_loss=0.5187\n",
      "Epoch 12: train_loss=0.4502, val_loss=0.5372\n",
      "Epoch 13: train_loss=0.4450, val_loss=0.4907\n",
      "Epoch 14: train_loss=0.4375, val_loss=0.4829\n",
      "Epoch 15: train_loss=0.4316, val_loss=0.5047\n",
      "Epoch 16: train_loss=0.4246, val_loss=0.5010\n",
      "Epoch 17: train_loss=0.4187, val_loss=0.4888\n",
      "Epoch 18: train_loss=0.4120, val_loss=0.4884\n",
      "Epoch 19: train_loss=0.4070, val_loss=0.5313\n",
      "Early stopping!\n",
      "‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh v√†o: E:\\NCKH - 2026\\ECG Project\\models\\resnet1d_attention_best.pth\n"
     ]
    }
   ],
   "source": [
    "# === 3Ô∏è‚É£ Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh ===\n",
    "num_classes = y_train.shape[1]\n",
    "model = ResNet1DAttention(num_classes=num_classes)\n",
    "print(model)\n",
    "\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    y_train=y_train,\n",
    "    num_epochs=25,\n",
    "    patience=5,\n",
    "    lr=1e-3,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh t·ªët nh·∫•t\n",
    "model_path = r\"E:\\NCKH - 2026\\ECG Project\\models\\resnet1d_attention_best.pth\"\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh v√†o: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d6bace-87aa-414b-989d-607fc5f5e814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      3257\n",
      "           1       0.49      0.87      0.62      1623\n",
      "           2       0.68      0.97      0.80      1615\n",
      "           3       0.79      0.94      0.86      1451\n",
      "           4       0.16      0.66      0.26       492\n",
      "           5       0.18      0.97      0.30       360\n",
      "           6       0.19      0.87      0.32       335\n",
      "           7       0.33      0.98      0.49       308\n",
      "\n",
      "   micro avg       0.52      0.91      0.66      9441\n",
      "   macro avg       0.47      0.90      0.57      9441\n",
      "weighted avg       0.67      0.91      0.74      9441\n",
      " samples avg       0.59      0.89      0.68      9441\n",
      "\n",
      "\n",
      "Confusion Matrices:\n",
      "Label 0:\n",
      "[[5393  320]\n",
      " [ 254 3003]]\n",
      "\n",
      "Label 1:\n",
      "[[5867 1480]\n",
      " [ 213 1410]]\n",
      "\n",
      "Label 2:\n",
      "[[6633  722]\n",
      " [  45 1570]]\n",
      "\n",
      "Label 3:\n",
      "[[7163  356]\n",
      " [  84 1367]]\n",
      "\n",
      "Label 4:\n",
      "[[6746 1732]\n",
      " [ 165  327]]\n",
      "\n",
      "Label 5:\n",
      "[[6979 1631]\n",
      " [  10  350]]\n",
      "\n",
      "Label 6:\n",
      "[[7414 1221]\n",
      " [  43  292]]\n",
      "\n",
      "Label 7:\n",
      "[[8050  612]\n",
      " [   6  302]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# === 4Ô∏è‚É£ ƒê√°nh gi√° m√¥ h√¨nh tr√™n test set ===\n",
    "preds_bin, preds, cms = evaluate_model(model, test_loader, y_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cdbc84f-290c-42c7-9a7f-13cbedcc3ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è D·ª± ƒëo√°n:\n",
      "Gi√° tr·ªã x√°c su·∫•t: [0.001 0.888 0.01  0.525 0.39  0.005 0.001 0.   ]\n",
      "Nh√£n nh·ªã ph√¢n: [0 1 0 1 0 0 0 0]\n",
      "Nh√£n th·∫≠t: [0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# === 5Ô∏è‚É£ Th·ª≠ d·ª± ƒëo√°n m·ªôt m·∫´u ECG ===\n",
    "model.eval()\n",
    "sample_signal, true_label = test_dataset[0]\n",
    "sample_signal = sample_signal.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = torch.sigmoid(model(sample_signal)).cpu().numpy().flatten()\n",
    "\n",
    "print(\"‚öôÔ∏è D·ª± ƒëo√°n:\")\n",
    "print(\"Gi√° tr·ªã x√°c su·∫•t:\", np.round(output, 3))\n",
    "print(\"Nh√£n nh·ªã ph√¢n:\", (output > 0.5).astype(int))\n",
    "print(\"Nh√£n th·∫≠t:\", true_label.numpy().astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8117acb8-be7e-4789-9cdb-b50cb581e6ac",
   "metadata": {},
   "source": [
    "# **INCEPTION TIME 34**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea7e7fc-4812-4943-991f-560060e8b883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionTime1D(\n",
      "  (block1): InceptionResidualBlock1D(\n",
      "    (inception): InceptionBlock1D(\n",
      "      (bottleneck): Conv1d(12, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "      (conv3): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "      (pool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (conv_pool): Conv1d(12, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (norm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (residual): Sequential(\n",
      "      (0): Conv1d(12, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (1): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (block2): InceptionResidualBlock1D(\n",
      "    (inception): InceptionBlock1D(\n",
      "      (bottleneck): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (conv1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "      (conv3): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "      (pool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (conv_pool): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (norm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (residual): Sequential(\n",
      "      (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (1): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (block3): InceptionResidualBlock1D(\n",
      "    (inception): InceptionBlock1D(\n",
      "      (bottleneck): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (conv1): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (conv2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "      (conv3): Conv1d(16, 32, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "      (pool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (conv_pool): Conv1d(64, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (norm): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (residual): Sequential(\n",
      "      (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (1): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (block4): InceptionResidualBlock1D(\n",
      "    (inception): InceptionBlock1D(\n",
      "      (bottleneck): Conv1d(128, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (conv1): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (conv2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "      (conv3): Conv1d(16, 32, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "      (pool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (conv_pool): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (norm): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (residual): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (1): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (block5): InceptionResidualBlock1D(\n",
      "    (inception): InceptionBlock1D(\n",
      "      (bottleneck): Conv1d(128, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (conv1): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (conv2): Conv1d(16, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "      (conv3): Conv1d(16, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "      (pool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (conv_pool): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (residual): Sequential(\n",
      "      (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (1): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (block6): InceptionResidualBlock1D(\n",
      "    (inception): InceptionBlock1D(\n",
      "      (bottleneck): Conv1d(256, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (conv1): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (conv2): Conv1d(16, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "      (conv3): Conv1d(16, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "      (pool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (conv_pool): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (residual): Sequential(\n",
      "      (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (1): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (block7): InceptionResidualBlock1D(\n",
      "    (inception): InceptionBlock1D(\n",
      "      (bottleneck): Conv1d(256, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (conv1): Conv1d(16, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (conv2): Conv1d(16, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "      (conv3): Conv1d(16, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "      (pool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (conv_pool): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (norm): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (residual): Sequential(\n",
      "      (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (1): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (block8): InceptionResidualBlock1D(\n",
      "    (inception): InceptionBlock1D(\n",
      "      (bottleneck): Conv1d(512, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (conv1): Conv1d(16, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (conv2): Conv1d(16, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "      (conv3): Conv1d(16, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "      (pool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (conv_pool): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (norm): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (residual): Sequential(\n",
      "      (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (1): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (attention): Attention(\n",
      "    (attn): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=8, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.8601, val_loss=0.6819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=0.6579, val_loss=0.5954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=0.5820, val_loss=0.5916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=0.5374, val_loss=0.6472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=0.5123, val_loss=0.5649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=0.4901, val_loss=0.5124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=0.4689, val_loss=0.4917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=0.4574, val_loss=0.5377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss=0.4446, val_loss=0.5013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss=0.4314, val_loss=0.4608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss=0.4233, val_loss=0.4809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss=0.4154, val_loss=0.4748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss=0.4039, val_loss=0.4652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss=0.3996, val_loss=0.4795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_loss=0.3945, val_loss=0.4500\n",
      "ƒê√£ l∆∞u m√¥ h√¨nh InceptionTime1D v√†o: E:\\NCKH - 2026\\ECG Project\\models\\inceptiontime1d_attention_best.pth\n"
     ]
    }
   ],
   "source": [
    "# === Hu·∫•n luy·ªán m√¥ h√¨nh InceptionTime1D + Attention ===\n",
    "num_classes = y_train.shape[1]\n",
    "model = InceptionTime1D(in_channels=12, num_classes=num_classes)\n",
    "print(model)\n",
    "\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    y_train=y_train,\n",
    "    num_epochs=15,\n",
    "    patience=5,\n",
    "    lr=1e-3,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# === L∆∞u m√¥ h√¨nh t·ªët nh·∫•t ===\n",
    "model_path = r\"E:\\NCKH - 2026\\ECG Project\\models\\inceptiontime1d_attention_best.pth\"\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"ƒê√£ l∆∞u m√¥ h√¨nh InceptionTime1D v√†o: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3db116-33f8-4235-9bab-1972a88c1482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      3257\n",
      "           1       0.77      0.87      0.82      1623\n",
      "           2       0.68      0.97      0.80      1615\n",
      "           3       0.85      0.95      0.90      1451\n",
      "           4       0.20      0.66      0.31       492\n",
      "           5       0.17      0.98      0.29       360\n",
      "           6       0.18      0.86      0.30       335\n",
      "           7       0.25      1.00      0.40       308\n",
      "\n",
      "   micro avg       0.55      0.94      0.70      9441\n",
      "   macro avg       0.50      0.91      0.59      9441\n",
      "weighted avg       0.72      0.94      0.79      9441\n",
      " samples avg       0.66      0.91      0.73      9441\n",
      "\n",
      "\n",
      "Confusion Matrices:\n",
      "Label 0:\n",
      "[[5324  389]\n",
      " [  59 3198]]\n",
      "\n",
      "Label 1:\n",
      "[[6919  428]\n",
      " [ 208 1415]]\n",
      "\n",
      "Label 2:\n",
      "[[6607  748]\n",
      " [  55 1560]]\n",
      "\n",
      "Label 3:\n",
      "[[7266  253]\n",
      " [  67 1384]]\n",
      "\n",
      "Label 4:\n",
      "[[7187 1291]\n",
      " [ 167  325]]\n",
      "\n",
      "Label 5:\n",
      "[[6849 1761]\n",
      " [   6  354]]\n",
      "\n",
      "Label 6:\n",
      "[[7317 1318]\n",
      " [  46  289]]\n",
      "\n",
      "Label 7:\n",
      "[[7724  938]\n",
      " [   1  307]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# === ƒê√°nh gi√° m√¥ h√¨nh tr√™n test set ===\n",
    "preds_bin, preds, cms = evaluate_model(model, test_loader, y_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6abf53d2-e287-4ab7-ab6f-2b6eb345a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_train.shape[1]  # ho·∫∑c ƒëi·ªÅn s·ªë class th·ªß c√¥ng, v√≠ d·ª• 5\n",
    "model = InceptionTime1D(in_channels=12, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "617ebc2d-59b2-44a2-a8ae-e095137cc157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ load l·∫°i m√¥ h√¨nh th√†nh c√¥ng!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_33088\\1361336070.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "model_path = r\"E:\\NCKH - 2026\\ECG Project\\models\\inceptiontime1d_attention_best.pth\"\n",
    "\n",
    "# Load v√†o model\n",
    "model.load_state_dict(torch.load(model_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "model.to(device)\n",
    "model.eval()  # chuy·ªÉn sang ch·∫ø ƒë·ªô suy lu·∫≠n\n",
    "print(\"ƒê√£ load l·∫°i m√¥ h√¨nh th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cc1936-10d1-4166-b687-6a26a3c227e9",
   "metadata": {},
   "source": [
    "# **T√åM NG∆Ø·ª†NG T·ªêT NH·∫§T**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aac77f89-2043-4207-86ac-29d49401f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.threshold_finder import find_best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cecf218b-edc3-4659-9c81-63032cb82106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "201f37e9-93d1-4119-b9fa-54d39c3fef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_val_true, y_val_pred_proba = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        logits = model(X_batch)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()  # multi-label => sigmoid\n",
    "        y_val_pred_proba.append(probs)\n",
    "        y_val_true.append(y_batch.cpu().numpy())\n",
    "\n",
    "y_val_true = np.vstack(y_val_true)\n",
    "y_val_pred_proba = np.vstack(y_val_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02fba080-96dd-417a-8b24-e979735b1d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best thresholds per class: [0.65 0.55 0.65 0.85 0.65 0.8  0.9  0.9 ]\n"
     ]
    }
   ],
   "source": [
    "best_thresholds = find_best_threshold(y_val_true, y_val_pred_proba)\n",
    "print(\"Best thresholds per class:\", np.round(best_thresholds, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a42b6947-0777-41c8-8e92-701a1f2b66a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Macro-F1 = 0.6464\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "        Nh·ªãp ch·∫≠m xoang       0.91      0.98      0.95      1632\n",
      " Nh·ªãp xoang b√¨nh th∆∞·ªùng       0.78      0.84      0.81       803\n",
      "              Cu·ªìng nhƒ©       0.71      0.92      0.80       813\n",
      "      Ch√™nh l√™n ƒëo·∫°n ST       0.95      0.91      0.93       741\n",
      "        Lo·∫°n nh·ªãp xoang       0.31      0.45      0.37       249\n",
      "               Rung nhƒ©       0.20      0.91      0.32       176\n",
      "    Ch√™nh xu·ªëng ƒëo·∫°n ST       0.41      0.55      0.47       182\n",
      "Tr·ª•c ƒëi·ªán tim l·ªách tr√°i       0.36      0.95      0.52       154\n",
      "\n",
      "              micro avg       0.68      0.89      0.77      4750\n",
      "              macro avg       0.58      0.82      0.65      4750\n",
      "           weighted avg       0.77      0.89      0.81      4750\n",
      "            samples avg       0.74      0.87      0.78      4750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- √Åp d·ª•ng threshold ---\n",
    "y_val_pred = (y_val_pred_proba > best_thresholds).astype(int)\n",
    "\n",
    "# --- T√≠nh F1 trung b√¨nh ---\n",
    "macro_f1 = f1_score(y_val_true, y_val_pred, average=\"macro\")\n",
    "print(f\"Validation Macro-F1 = {macro_f1:.4f}\\n\")\n",
    "\n",
    "# --- In b√°o c√°o chi ti·∫øt ---\n",
    "target_names = [\n",
    "    \"Nh·ªãp ch·∫≠m xoang\", \"Nh·ªãp xoang b√¨nh th∆∞·ªùng\", \"Cu·ªìng nhƒ©\", \"Ch√™nh l√™n ƒëo·∫°n ST\", \"Lo·∫°n nh·ªãp xoang\",\n",
    "    \"Rung nhƒ©\", \"Ch√™nh xu·ªëng ƒëo·∫°n ST\", \"Tr·ª•c ƒëi·ªán tim l·ªách tr√°i\"\n",
    "]\n",
    "report = classification_report(y_val_true, y_val_pred, target_names=target_names, zero_division=0)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d0fad38-9371-40cb-a936-02a1e18cf01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and thresholds!\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"../models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), f\"{save_dir}/resnet3_best.pth\")\n",
    "np.save(f\"{save_dir}/best_thresholds_r3.npy\", best_thresholds)\n",
    "\n",
    "print(\"Saved model and thresholds!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a21703-d860-4fc0-8367-f66e9ca71b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
