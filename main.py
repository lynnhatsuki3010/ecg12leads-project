# main.py
"""
MAIN PIPELINE â€” ECG 12-Lead Classification
-------------------------------------------
Quy trÃ¬nh chÃ­nh gá»“m:
1ï¸âƒ£ Tiá»n xá»­ lÃ½ WFDB vÃ  táº¡o metadata sáº¡ch
2ï¸âƒ£ PhÃ¢n tÃ­ch vÃ  trá»±c quan hÃ³a top bá»‡nh
3ï¸âƒ£ Huáº¥n luyá»‡n mÃ´ hÃ¬nh ResNet1D + Attention
4ï¸âƒ£ ÄÃ¡nh giÃ¡ vÃ  tÃ¬m ngÆ°á»¡ng tá»‘i Æ°u
"""

import os
import torch
import numpy as np
import pandas as pd
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report

# === Import ná»™i bá»™ ===
from processing.preprocess import run_preprocessing
from visualize.plot_statistics import analyze_top_diseases
from misc.gpu_check import check_gpu
from misc.threshold_finder import find_best_threshold
from training.model import ResNet1DAttention
from training.train import train_model
from training.evaluate import evaluate_model
from training.dataset_loader import ECGDataset


# === Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n ===
ROOT_DIR = r"E:\NCKH - 2026\ECG Project"
WFDB_DIR = os.path.join(ROOT_DIR, "data\raw\WFDBRecords")
SNOMED_PATH = os.path.join(ROOT_DIR, "data\raw\ConditionNames_SNOMED-CT.csv")
METADATA_CLEAN = os.path.join(ROOT_DIR, "data\processed\patient_metadata_clean.xlsx")
SPLIT_DIR = os.path.join(ROOT_DIR, "data")


# ============================================================
def main(mode="train"):
    """
    mode: "preprocess", "analyze", hoáº·c "train"
    """
    print("ğŸš€ Báº®T Äáº¦U PIPELINE ECG 12-LEAD\n")

    # === (1) Tiá»n xá»­ lÃ½ dá»¯ liá»‡u ===
    if mode in ["preprocess", "train"]:
        print("ğŸ”¹ BÆ°á»›c 1: Táº¡o vÃ  lÃ m sáº¡ch metadata tá»« WFDB...")
        run_preprocessing()

    # === (2) PhÃ¢n tÃ­ch thá»‘ng kÃª ===
    if mode in ["analyze", "train"]:
        print("\nğŸ”¹ BÆ°á»›c 2: PhÃ¢n tÃ­ch top bá»‡nh phá»• biáº¿n...")
        analyze_top_diseases(METADATA_CLEAN, SNOMED_PATH, top_n=10)

    if mode == "preprocess" or mode == "analyze":
        print("\nâœ… HoÃ n táº¥t cháº¿ Ä‘á»™ rÃºt gá»n:", mode)
        return

    # === (3) Kiá»ƒm tra GPU ===
    print("\nğŸ”¹ BÆ°á»›c 3: Kiá»ƒm tra GPU...")
    device = check_gpu()

    # === (4) Load split files ===
    print("\nğŸ”¹ BÆ°á»›c 4: Chuáº©n bá»‹ dataset & DataLoader...")

    def load_split_file(filename):
        path = os.path.join(SPLIT_DIR, filename)
        if not os.path.exists(path):
            raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y file split: {path}")
        return np.load(path, allow_pickle=True)

    train_files = load_split_file("train_files.npy")
    val_files   = load_split_file("val_files.npy")
    test_files  = load_split_file("test_files.npy")
    y_train     = load_split_file("y_train.npy")
    y_val       = load_split_file("y_val.npy")
    y_test      = load_split_file("y_test.npy")

    # Táº¡o dataset
    train_dataset = ECGDataset(train_files, y_train, augment=True)
    val_dataset   = ECGDataset(val_files, y_val, augment=False)
    test_dataset  = ECGDataset(test_files, y_test, augment=False)

    # DataLoader
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
    val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)
    test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)

    print(f"âœ… Dataset: {len(train_loader)} train batches, {len(val_loader)} val, {len(test_loader)} test")

    # === (5) Khá»Ÿi táº¡o & huáº¥n luyá»‡n mÃ´ hÃ¬nh ===
    print("\nğŸ”¹ BÆ°á»›c 5: Huáº¥n luyá»‡n mÃ´ hÃ¬nh ResNet1D + Attention...")
    model = ResNet1DAttention(num_classes=y_train.shape[1])
    model = train_model(model, train_loader, val_loader, device=device)

    # === (6) ÄÃ¡nh giÃ¡ sÆ¡ bá»™ ===
    print("\nğŸ”¹ BÆ°á»›c 6: ÄÃ¡nh giÃ¡ sÆ¡ bá»™ trÃªn test set...")
    evaluate_model(model, test_loader, y_test, device=device)

    # === (7) TÃ­nh xÃ¡c suáº¥t & tÃ¬m ngÆ°á»¡ng tá»‘i Æ°u ===
    print("\nğŸ”¹ BÆ°á»›c 7: TÃ¬m ngÆ°á»¡ng tá»‘i Æ°u theo F1-score...")
    model.eval()
    y_true, y_pred_proba = [], []
    with torch.no_grad():
        for X_batch, y_batch in test_loader:
            X_batch = X_batch.to(device)
            outputs = torch.sigmoid(model(X_batch))
            y_true.append(y_batch.numpy())
            y_pred_proba.append(outputs.cpu().numpy())

    y_true = np.vstack(y_true)
    y_pred_proba = np.vstack(y_pred_proba)
    best_thresholds = find_best_threshold(y_true, y_pred_proba)
    print("âœ… NgÆ°á»¡ng tá»‘i Æ°u tá»«ng class:", np.round(best_thresholds, 3))

    # === (8) ÄÃ¡nh giÃ¡ cuá»‘i cÃ¹ng ===
    print("\nğŸ”¹ BÆ°á»›c 8: ÄÃ¡nh giÃ¡ cuá»‘i cÃ¹ng vá»›i ngÆ°á»¡ng tá»‘i Æ°u...")
    y_pred = (y_pred_proba > best_thresholds).astype(int)
    print(classification_report(
        y_true, y_pred, target_names=[f"Class_{i}" for i in range(y_pred.shape[1])]
    ))

    print("\nğŸ¯ HOÃ€N Táº¤T PIPELINE â€” MÃ” HÃŒNH Sáº´N SÃ€NG ÄÃNH GIÃ VÃ€ Dá»° ÄOÃN.")


# ============================================================
if __name__ == "__main__":
    # Thay Ä‘á»•i mode tÃ¹y nhu cáº§u: "preprocess", "analyze", hoáº·c "train"
    main(mode="train")
